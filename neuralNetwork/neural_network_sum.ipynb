{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import important modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 15:25:20.059433: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 15:25:20.154190: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 15:25:20.157203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 15:25:22.045010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = np.random.randint(0, 40, (50, 2))\n",
    "\n",
    "input_list = np.random.randint(0, 40, (50, 2))\n",
    "\n",
    "output_list = input_list[:, 0] + input_list[:, 1]\n",
    "\n",
    "# reshape the result array to a column vector\n",
    "output_list = output_list.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list_train, input_list_test, output_list_train, output_list_test = train_test_split(input_list, output_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1112\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1063\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1014\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0965\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0917\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0868\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0820\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0773\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0725\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0678\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0631\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0584\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0537\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0491\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0444\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0399\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0353\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0308\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0263\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0218\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0174\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0129\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0085\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0042\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9998\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9955\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9911\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9868\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9826\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9783\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9741\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9699\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9657\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9615\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9574\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9532\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9491\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9450\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9410\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9369\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9329\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9289\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9249\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9210\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9170\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9131\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9092\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9053\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9015\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8976\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8938\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8900\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8862\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8824\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8787\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8749\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8712\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8675\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8638\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a89f2f6d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_list, output_list, epochs=60, batch_size=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions with our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n",
      "          prediction     actual\n",
      "80+70:    145.01169      150\n",
      "50+30:    74.90214       80\n",
      "90+100:   186.26772      190\n"
     ]
    }
   ],
   "source": [
    "new_input = np.array([[80, 70], [50, 30], [90, 100]])\n",
    "predictions = model.predict(new_input)\n",
    "print(\"{:<10s}{:<15s}{}\".format(\" \", \"prediction\", \"actual\"))\n",
    "for i in range(len(predictions)):\n",
    "    x, y = new_input[i]\n",
    "    predicted_val = predictions[i][0]\n",
    "    actual_val = x + y\n",
    "    print(\"{:<10s}{:<15s}{}\".format(str(x) + \"+\" + str(y) + \":\", str(predicted_val), str(actual_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Ultimate AI that we just made!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8098\n",
      "score:0.5525615560370467\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(input_list_test, output_list_test)\n",
    "score = 1 / (1 + loss)  # Convert the loss to a score\n",
    "print(\"score:\" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this model is already exported, if not export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/martin/Desktop/pythonShit/simplePythonAI/preTrainedModels/NN-Sum.pkl\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "oneUp = pathlib.Path(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "preModels = pathlib.Path('preTrainedModels')\n",
    "pkFile = oneUp.joinpath(preModels).joinpath(\"NN-Sum.pkl\")\n",
    "print(pkFile)\n",
    "#pkFile = os.path.join(os.path.dirname(os.getcwd()), r\"preTrainedModels\\NN-Sum.pkl\")\n",
    "print(os.path.exists(pkFile))\n",
    "with open(pkFile, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkFile, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    print(\"data type\"+str(type(data)))\n",
    "    numbers = np.array([[15, 15]])\n",
    "    prediction = data.predict(numbers)\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d5efd4f713d6472d8e095071f69ead853a26a7a33f622d79957dffab2d85ef0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
